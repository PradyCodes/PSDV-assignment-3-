{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649292d8-1d44-433d-b740-5091534c307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1788a18c-ceaa-4da1-97fe-5414be4860da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/PSDV assignment 3/Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/PSDV assignment 3/Data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m state\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/PSDV assignment 3/State_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m ncap_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/PSDV assignment 3/NCAP_Funding.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/PSDV assignment 3/Data.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/Data.csv')\n",
    "state= pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/State_data.csv')\n",
    "ncap_data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/NCAP_Funding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e0406c-5bf4-4add-a713-ebdff318f98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   S. No.           State           City Amount released during FY 2019-20  \\\n",
      "0       1  Andhra Pradesh      Vijaywada                                 6   \n",
      "1       2  Andhra Pradesh         Guntur                              0.12   \n",
      "2       3  Andhra Pradesh        Kurnool                              0.06   \n",
      "3       4  Andhra Pradesh        Nellore                              0.06   \n",
      "4       5  Andhra Pradesh  Visakhapatnam                              0.12   \n",
      "\n",
      "  Amount released during FY 2020-21 Amount released during FY 2021-22  \\\n",
      "0                                 -                                 -   \n",
      "1                              0.76                              1.96   \n",
      "2                              0.76                              1.36   \n",
      "3                              0.76                              1.92   \n",
      "4                                 -                                 -   \n",
      "\n",
      "   Total fund released Utilisation as on June 2022  \n",
      "0                 6.00                       22.91  \n",
      "1                 2.84                       22.91  \n",
      "2                 2.18                       22.91  \n",
      "3                 2.74                       22.91  \n",
      "4                 0.12                       22.91  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\Data.csv\")\n",
    "state_data = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\State_data.csv\")\n",
    "ncap_data = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\NCAP_Funding.csv\")\n",
    "print(ncap_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be68ccd-dd37-4db7-b7db-afc9e9120f25",
   "metadata": {},
   "source": [
    "## Spatial aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb089ebc-8b31-4961-8940-6aa09a6b348c",
   "metadata": {},
   "source": [
    "#### Which state (consider all stations in that state) has the highest average PM2.5 concentration across all stations and across all years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13933cd5-97b2-4cc7-b69f-a45f1f1d5567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.1009176780069\n",
      "state\n",
      "Andhra Pradesh        35.049347\n",
      "Arunachal Pradesh     22.674513\n",
      "Assam                 57.962372\n",
      "Bihar                 76.918759\n",
      "Chandigarh            56.666803\n",
      "Chhattisgarh          28.761571\n",
      "Delhi                104.100918\n",
      "Gujarat               52.462657\n",
      "Haryana               72.371070\n",
      "Himachal Pradesh      62.516878\n",
      "Jammu and Kashmir     28.574696\n",
      "Jharkhand             54.281545\n",
      "Karnataka             28.894840\n",
      "Kerala                29.404793\n",
      "Madhya Pradesh        45.874375\n",
      "Maharashtra           43.491415\n",
      "Manipur               34.911856\n",
      "Meghalaya             24.513390\n",
      "Mizoram               11.784922\n",
      "Nagaland              33.439550\n",
      "Odisha                52.109504\n",
      "Puducherry            22.854171\n",
      "Punjab                52.243166\n",
      "Rajasthan             54.230341\n",
      "Sikkim                13.474286\n",
      "Tamil Nadu            31.289620\n",
      "Telangana             38.114469\n",
      "Tripura               57.927642\n",
      "Uttar Pradesh         70.893996\n",
      "Uttarakhand           36.788767\n",
      "West Bengal           54.611086\n",
      "Name: PM2.5, dtype: float64\n",
      "Delhi has maximum avg PM 2.5 concentration\n"
     ]
    }
   ],
   "source": [
    "avg_pm25 = data.groupby('state')[\"PM2.5\"].mean()\n",
    "print(avg_pm25['Delhi'])\n",
    "print(avg_pm25)\n",
    "\n",
    "print(f\"{avg_pm25.idxmax()} has maximum avg PM 2.5 concentration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4e84a-9e36-409a-a58f-456f355b3234",
   "metadata": {},
   "source": [
    "#### Which state (consider all stations in that state) had the most days with hazardous PM2.5 levels (above 300 µg/m³) for the year 2023?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2da8fa-812e-4afc-b724-4eaded93aa1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Timestamp                                  station       PM2.5  \\\n",
      "178      2017-01-01                        ITO, Delhi - CPCB  524.697917   \n",
      "733      2017-01-02  IGSC Planetarium Complex, Patna - BSPCB  352.321190   \n",
      "739      2017-01-02                        ITO, Delhi - CPCB  399.011111   \n",
      "1110     2017-01-02            Vikas Sadan, Gurugram - HSPCB  344.078958   \n",
      "1556     2017-01-03              Sanjay Palace, Agra - UPPCB  324.958333   \n",
      "...             ...                                      ...         ...   \n",
      "1618520  2024-11-25                     Bawana, Delhi - DPCC  308.390000   \n",
      "1618898  2024-11-25                     Rohini, Delhi - DPCC  307.600000   \n",
      "1619037  2024-11-25                Vivek Vihar, Delhi - DPCC  311.350000   \n",
      "1619779  2024-11-27  IGSC Planetarium Complex, Patna - BSPCB  437.110000   \n",
      "1620203  2024-11-28                     Bawana, Delhi - DPCC  310.780000   \n",
      "\n",
      "               PM10              address      city   latitude  longitude  \\\n",
      "178      568.562500                  NaN     Delhi  28.628624  77.241060   \n",
      "733             NaN                  NaN     Patna  25.610369  85.132568   \n",
      "739      463.325843                  NaN     Delhi  28.628624  77.241060   \n",
      "1110            NaN                  NaN  Gurugram  28.450124  77.026305   \n",
      "1556            NaN                  NaN      Agra  27.198658  78.005981   \n",
      "...             ...                  ...       ...        ...        ...   \n",
      "1618520  419.790000                  NaN     Delhi  28.776200  77.051074   \n",
      "1618898  423.330000                  NaN     Delhi  28.732528  77.119920   \n",
      "1619037  445.510000  Vivek Vihar, 110095     Delhi  28.672342  77.315260   \n",
      "1619779         NaN                  NaN     Patna  25.610369  85.132568   \n",
      "1620203  485.530000                  NaN     Delhi  28.776200  77.051074   \n",
      "\n",
      "                 state  \n",
      "178              Delhi  \n",
      "733              Bihar  \n",
      "739              Delhi  \n",
      "1110           Haryana  \n",
      "1556     Uttar Pradesh  \n",
      "...                ...  \n",
      "1618520          Delhi  \n",
      "1618898          Delhi  \n",
      "1619037          Delhi  \n",
      "1619779          Bihar  \n",
      "1620203          Delhi  \n",
      "\n",
      "[5814 rows x 9 columns]\n",
      "Delhi had the most days with hazardous PM2.5 levels (above 300 µg/m³) for the year 2023\n",
      "3371\n"
     ]
    }
   ],
   "source": [
    "filtered_df = data[data[\"PM2.5\"]>300]\n",
    "print(filtered_df)\n",
    "df_2 = filtered_df.groupby(\"state\")['station'].count()\n",
    "print(f\"{df_2.idxmax()} had the most days with hazardous PM2.5 levels (above 300 µg/m³) for the year 2023\")\n",
    "print(df_2[df_2.idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74be36e-6ed0-4e97-86fe-16747f585f66",
   "metadata": {},
   "source": [
    "#### Which state has the highest variability in PM2.5 levels across its monitoring stations in 2023? (Think how would you measure variability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2be2ff0-715a-4ce8-a700-8b21aaaee60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi has the highest variability in PM2.5 levels across its monitoring stations in 2023\n"
     ]
    }
   ],
   "source": [
    "df_3 = data.groupby('state')[\"PM2.5\"].std()\n",
    "print(f\"{df_3.idxmax()} has the highest variability in PM2.5 levels across its monitoring stations in 2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244bd046-9cf0-4805-adcd-7ac456fc7cb1",
   "metadata": {},
   "source": [
    "#### Which state has the lowest average PM2.5 levels during the Covid period (The year 2020-2021 both years inclusive)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "608c2bf3-0fdc-4d75-a570-e2349d0b4288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mizoram has the lowest average PM2.5 levels during the Covid period (The year 2020-2021 both years inclusive)\n"
     ]
    }
   ],
   "source": [
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "df_4 = data[(data[\"Timestamp\"].dt.year>=2020) & (data[\"Timestamp\"].dt.year<=2021)]\n",
    "# print(df_4,\"\\n\")\n",
    "df_5 = df_4.groupby('state')['PM2.5'].mean()\n",
    "df_5.reset_index()\n",
    "# print(df_5)\n",
    "minimum = df_5.idxmin()\n",
    "print(f\"{minimum} has the lowest average PM2.5 levels during the Covid period (The year 2020-2021 both years inclusive)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53643c32-af26-4890-bbbf-5bfbc64e6101",
   "metadata": {},
   "source": [
    "## Temporal Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532eb0e1-4988-491b-9bd4-a7945f4d740b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)      \u001b[38;5;66;03m# Convert Timestamp column to datetime format\u001b[39;00m\n\u001b[0;32m      7\u001b[0m august_2020 \u001b[38;5;241m=\u001b[39m data[(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2020\u001b[39m) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m8\u001b[39m)]   \u001b[38;5;66;03m# Filter data for August 2020\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\Anaconda_setup\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format=\"%Y-%m-%d\")      # Convert Timestamp column to datetime format\n",
    "\n",
    "august_2020 = data[(data['Timestamp'].dt.year == 2020) & (data['Timestamp'].dt.month == 8)]   # Filter data for August 2020\n",
    "\n",
    "max_pm25_row = august_2020.loc[august_2020['PM2.5'].idxmax()]      # Find the station with the highest PM2.5 value\n",
    "\n",
    "# Print the station details\n",
    "print(f\"Station with highest PM2.5 in August 2020: {max_pm25_row['station']}\")\n",
    "print(f\"PM2.5 Value: {max_pm25_row['PM2.5']}\")\n",
    "print(f\"city: {max_pm25_row['city']}, state: {max_pm25_row['state']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366fe604-353d-47d0-8241-b40d1136dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format=\"%Y-%m-%d\")     # Convert Timestamp column to datetime format\n",
    "\n",
    "# Filter data for the year 2018\n",
    "data_2018 = data[(data['Timestamp'].dt.year == 2018) & (data['station']=='Lal Bahadur Shastri Nagar, Kalaburagi - KSPCB')]\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [12,1,2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3,4,5]:\n",
    "        return 'Summer'\n",
    "    elif month in [6,7,8,9]:\n",
    "        return 'Monsoon'\n",
    "    return \"Other\"\n",
    "\n",
    "# Assign seasons\n",
    "data_2018['season'] = data_2018['Timestamp'].dt.month.apply(get_season)\n",
    "\n",
    "seasonal_avg_pm25 = data_2018.groupby('season')['PM2.5'].mean()              # Calculate average PM2.5 for each season\n",
    "\n",
    "most_polluted_season = seasonal_avg_pm25.idxmax()           # Identify the season with the highest pollution\n",
    "\n",
    "print(\"Average PM2.5 concentration for each season in 2018:\")\n",
    "print(seasonal_avg_pm25)\n",
    "print(f\"\\nSeason with highest pollution: {most_polluted_season}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2dc6e-8984-492b-9648-7e9760996762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format=\"%Y-%m-%d\")          # Convert Timestamp column to datetime format\n",
    "\n",
    "station_name = \"Lal Bahadur Shastri Nagar, Kalaburagi - KSPCB\"                   # Filter data for the year 2021 and the required station\n",
    "data_2021 = data[(data['Timestamp'].dt.year == 2021) & (data['station'] == station_name)]\n",
    "\n",
    "data_2021['Day_Type'] = data_2021['Timestamp'].dt.dayofweek.map(lambda x: 'Weekend' if x >= 5 else 'Weekday')  # Create a column for weekdays (0-4) and weekends (5-6)\n",
    "\n",
    "# Extract month for grouping\n",
    "data_2021['Month'] = data_2021['Timestamp'].dt.month\n",
    "\n",
    "# Calculate monthly average PM2.5 for weekdays and weekends separately\n",
    "monthly_avg_pm25 = data_2021.groupby(['Month', 'Day_Type'])['PM2.5'].mean().unstack()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_avg_pm25.index, monthly_avg_pm25['Weekday'], marker='o', linestyle='-', label='Weekdays')\n",
    "plt.plot(monthly_avg_pm25.index, monthly_avg_pm25['Weekend'], marker='s', linestyle='-', label='Weekends')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average PM2.5 Levels\")\n",
    "plt.title(\"Comparison of Average PM2.5 Levels on Weekdays and Weekends (2021)\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19deb2bc-5566-489d-87b1-1ef58dbfc110",
   "metadata": {},
   "source": [
    "## Spatio Temporal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a65169-fc90-4eaa-84f6-3a3666161de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[\"Timestamp\"] = pd.to_datetime(data[\"Timestamp\"], format=\"%Y-%m-%d\")    # Convert Timestamp to datetime format\n",
    "\n",
    "data_2022 = data[data[\"Timestamp\"].dt.year == 2022]          # Filter for the year 2022\n",
    "\n",
    "data_2022[\"Month\"] = data_2022[\"Timestamp\"].dt.month       # Extract months and define season masks\n",
    "summer_months = [3, 4, 5]\n",
    "monsoon_months = [6, 7, 8, 9]\n",
    "\n",
    "# Compute average PM2.5 for each state in summer and monsoon\n",
    "summer_avg = data_2022[data_2022[\"Month\"].isin(summer_months)].groupby(\"state\")[\"PM2.5\"].mean()\n",
    "monsoon_avg = data_2022[data_2022[\"Month\"].isin(monsoon_months)].groupby(\"state\")[\"PM2.5\"].mean()\n",
    "\n",
    "# Combine and calculate percentage change\n",
    "seasonal_change = pd.DataFrame({\n",
    "    \"Summer_Avg_PM2.5\": summer_avg,\n",
    "    \"Monsoon_Avg_PM2.5\": monsoon_avg\n",
    "})\n",
    "seasonal_change[\"Percentage_Change\"] = ((seasonal_change[\"Monsoon_Avg_PM2.5\"] - seasonal_change[\"Summer_Avg_PM2.5\"]) / seasonal_change[\"Summer_Avg_PM2.5\"]) * 100\n",
    "\n",
    "# Identify the state with the maximum absolute percentage change\n",
    "max_change_state = seasonal_change[\"Percentage_Change\"].abs().idxmax()\n",
    "max_change_value = seasonal_change.loc[max_change_state, \"Percentage_Change\"]\n",
    "\n",
    "print(f\"State with the most difference in PM2.5 levels: {max_change_state} ({max_change_value:.2f}% change)\")   # Display result\n",
    "print(seasonal_change.sort_values(by=\"Percentage_Change\", ascending=False))    # Display full table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f2cfa-e045-49ec-bfe7-95482578e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d')           # Convert the Timestamp column to datetime format\n",
    "\n",
    "delhi_data = df[df['city'] == 'Delhi']                    # Filter data for Delhi\n",
    "\n",
    "delhi_data['Year'] = delhi_data['Timestamp'].dt.year        # Extract year and month from Timestamp\n",
    "delhi_data['Month'] = delhi_data['Timestamp'].dt.month\n",
    "\n",
    "def get_season(month):                     # Function to determine season based on month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Monsoon'\n",
    "\n",
    "delhi_data['Season'] = delhi_data['Month'].apply(get_season)        # Apply the get_season function to create a new 'Season' column\n",
    "\n",
    "delhi_data = delhi_data[(delhi_data['Year'] >= 2017) & (delhi_data['Year'] <= 2023)] # Filter the data for the years 2017-2023\n",
    "\n",
    "# Calculate the average PM2.5 levels for each season across the years\n",
    "avg_pm25_season = delhi_data.groupby(['Season', 'Year'])['PM2.5'].mean().reset_index()\n",
    "\n",
    "# Now, pivot the data to have years as columns for easier plotting\n",
    "avg_pm25_pivot = avg_pm25_season.pivot(index='Season', columns='Year', values='PM2.5')\n",
    "\n",
    "plt.figure(figsize=(10, 6))                                                              # Plotting the results\n",
    "avg_pm25_pivot.plot(kind='line', marker='o', linestyle='-', markersize=6, linewidth=2)\n",
    "\n",
    "plt.title('Average PM2.5 Levels for Delhi Across Seasons (2017-2023)', fontsize=14)    # Adding labels and title\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Average PM2.5 (µg/m³)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()         # Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3ec45-047c-48ca-8eb7-da4726a983ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d')\n",
    "\n",
    "cities_data = df[df['city'].isin(['Delhi', 'Mumbai'])]             # Filter data for Delhi and Mumbai\n",
    "\n",
    "cities_data['Year'] = cities_data['Timestamp'].dt.year           # Extract year and month from Timestamp\n",
    "cities_data['Month'] = cities_data['Timestamp'].dt.month\n",
    "\n",
    "cities_data = cities_data[(cities_data['Year'] >= 2017) & (cities_data['Year'] <= 2023)]        # Filter data for the years 2017-2023\n",
    "\n",
    "avg_pm25_cities = cities_data.groupby(['city', 'Year', 'Month'])['PM2.5'].mean().reset_index()    # Calculate the monthly average PM2.5 for both cities\n",
    "\n",
    "avg_pm25_cities['Date'] = pd.to_datetime(avg_pm25_cities[['Year', 'Month']].assign(DAY=1))   # Create a datetime column for plotting\n",
    "\n",
    "avg_pm25_pivot = avg_pm25_cities.pivot(index='Date', columns='city', values='PM2.5')     # Pivot the data so we have separate columns for Delhi and Mumbai\n",
    "\n",
    "plt.figure(figsize=(12, 6))      # Plotting the time-series graph\n",
    "avg_pm25_pivot.plot(kind='line', marker='o', linestyle='-', markersize=4, linewidth=2)\n",
    "\n",
    "plt.title('Time-Series of PM2.5 Levels in Delhi and Mumbai (2017-2023)', fontsize=14)    # Adding labels and title\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('PM2.5 (µg/m³)', fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()    # ploting\n",
    "plt.show()\n",
    "\n",
    "delhi_fluctuation = avg_pm25_pivot['Delhi'].std()           # Calculate fluctuations (standard deviation) for each city\n",
    "mumbai_fluctuation = avg_pm25_pivot['Mumbai'].std()\n",
    "\n",
    "print(f\"Delhi's PM2.5 fluctuation (std dev): {delhi_fluctuation:.2f}\")\n",
    "print(f\"Mumbai's PM2.5 fluctuation (std dev): {mumbai_fluctuation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e558f9b-9b61-478c-9535-2be5d3641f26",
   "metadata": {},
   "source": [
    "## Population-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230facd-c96d-42e0-9f87-4f078961c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/Data.csv')\n",
    "state= pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/State_data.csv')\n",
    "#so that columns name is same in both\n",
    "state.rename(columns={\"State\":\"state\"}, inplace=True)\n",
    "#grouped stations by state and counted them in a new dataframe\n",
    "station_per_state = data.groupby('state')['station'].count().reset_index()\n",
    "#merged count of stations and population dataframes\n",
    "merged_df = station_per_state.merge(state, on='state', how='outer')\n",
    "#added new column of perpopulation station count\n",
    "merged_df[\"Station_per_population\"]=merged_df[\"station\"]/merged_df[\"Population\"]\n",
    "#found the max and created a mask. applied the mask and printed the state name\n",
    "print(merged_df[merged_df[\"Station_per_population\"]==max(merged_df[\"Station_per_population\"])][\"state\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee9dfc-0cd8-4dbd-9287-ffbd2a19bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/Data.csv')\n",
    "state= pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/State_data.csv')\n",
    "#so that columns name is same in both\n",
    "state.rename(columns={\"State\":\"state\"}, inplace=True)\n",
    "#converting string entry to datetime entry in timestamp cloumn\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "#masking for year 2023 and applying the mask and creating a new df from it\n",
    "data_2023 = data[data['Timestamp'].dt.year == 2023]\n",
    "#grouping the pm25 by states and summing all of it\n",
    "pm25_per_state = data_2023.groupby('state')['PM2.5'].sum().reset_index()\n",
    "#merging pm25 year 2023 data df with population df\n",
    "merged_df = pm25_per_state.merge(state, on='state', how='outer')\n",
    "#added new column of percapita pm25 pollution\n",
    "merged_df[\"percapita_polution\"]=merged_df[\"PM2.5\"]/merged_df[\"Population\"]\n",
    "#sorting pm25 in descending\n",
    "merged_df.sort_values(\"percapita_polution\", ascending=False, inplace=True)\n",
    "#top5\n",
    "top5_poluted=merged_df[:5]\n",
    "\n",
    "#bargraph\n",
    "bargraph= plt.pyplot\n",
    "bargraph.figure(figsize=(12, 6))  # Adjust figure size as needed\n",
    "bargraph.bar(top5_poluted['state'], top5_poluted['percapita_polution'])\n",
    "bargraph.xlabel(\"State\")\n",
    "bargraph.ylabel(\"Per Capita PM2.5 levels\")\n",
    "bargraph.title(\"per capita PM2.5 exposure in 2023\")\n",
    "bargraph.tight_layout()\n",
    "bargraph.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c712ea8-5ded-4ba5-9a1e-4c70a03a66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/Data.csv')\n",
    "state= pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/State_data.csv')\n",
    "#so that columns name is same in both\n",
    "state.rename(columns={\"State\":\"state\"}, inplace=True)\n",
    "#creating population density column in state df\n",
    "state[\"Population_density\"]=state[\"Population\"]/state[\"Area (km2)\"]\n",
    "#grouping the pm25 by states and averaging all of it\n",
    "pm25_per_state = data.groupby('state')['PM2.5'].mean().reset_index()\n",
    "#merging pm25 data df with population df\n",
    "merged_df = pm25_per_state.merge(state, on='state', how='outer')\n",
    "\n",
    "#scatter plt\n",
    "sct= plt.pyplot\n",
    "sct.scatter(merged_df['Population_density'], merged_df['PM2.5'])\n",
    "sct.xlabel(\"Population_density\")\n",
    "sct.ylabel(\"average PM2.5 levels\")\n",
    "sct.tight_layout()\n",
    "sct.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723ffed-712e-49e4-b424-8fd3f0a4153f",
   "metadata": {},
   "source": [
    "## Area Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc08cf9-a0f3-4e22-bbc9-ffaea75a0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/Data.csv')\n",
    "state= pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/State_data.csv')#contains population and area details\n",
    "#so that columns name is same in both dfs\n",
    "state.rename(columns={\"State\":\"state\"}, inplace=True)\n",
    "#grouping the pm25 by states and summing all of it\n",
    "pm25_per_state = data.groupby('state')['PM2.5'].sum().reset_index()\n",
    "#merging pm25 data df with area df\n",
    "merged_df = pm25_per_state.merge(state, on='state', how='outer')\n",
    "#to find PM2.5 concentration per square kilometer\n",
    "merged_df[\"PM2.5_km2\"]= merged_df['PM2.5']/merged_df[\"Area (km2)\"]\n",
    "\n",
    "#bar plt\n",
    "brgr= plt.pyplot\n",
    "brgr.figure(figsize=(10, 20))\n",
    "brgr.bar(merged_df['state'], merged_df['PM2.5_km2'])\n",
    "brgr.xlabel(\"state\")\n",
    "brgr.xticks(rotation=90)\n",
    "brgr.ylabel(\"average PM2.5 per square kilometer\")\n",
    "brgr.tight_layout()\n",
    "brgr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eb077-fcd2-41ee-89cb-094693be5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/Data.csv')\n",
    "state= pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/State_data.csv')#contains population and area details\n",
    "#so that columns name is same in both dfs\n",
    "state.rename(columns={\"State\":\"state\"}, inplace=True)\n",
    "#grouping the pm25 by states and summing all of it\n",
    "pm25_per_state = data.groupby('state')['station'].sum().reset_index()\n",
    "#merging pm25 data df with area df\n",
    "merged_df = pm25_per_state.merge(state, on='state', how='outer')\n",
    "#to find PM2.5 concentration per square kilometer\n",
    "merged_df[\"station_km2\"]= merged_df['station']/merged_df[\"Area (km2)\"]\n",
    "merged_df.sort_values(\"station_km2\", ascending=False, inplace=True)\n",
    "#bar plt\n",
    "brgr= plt.pyplot\n",
    "brgr.figure(figsize=(10, 20))\n",
    "brgr.bar(merged_df['state'], merged_df['Station_km2'])\n",
    "brgr.xlabel(\"state\")\n",
    "brgr.xticks(rotation=90)\n",
    "brgr.ylabel(\"average station per square kilometer\")\n",
    "brgr.tight_layout()\n",
    "brgr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784faea-bafe-4a8e-a4ea-58b9beb24a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "data = pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/Data.csv')\n",
    "state= pd.read_csv('/content/drive/MyDrive/PSDV assignment 3/State_data.csv')\n",
    "#so that columns name is same in both\n",
    "state.rename(columns={\"State\":\"state\"}, inplace=True)\n",
    "#converting string entry to datetime entry in timestamp cloumn\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "#masking for year 2021 and applying the mask and creating a new df from it\n",
    "data_2021 = data[data['Timestamp'].dt.year == 2021]\n",
    "\n",
    "#grouping the pm25 by states and summing all of it\n",
    "pm25_per_state = data_2021.groupby('state')['PM2.5'].mean().reset_index()\n",
    "#merging pm25 year 2021 data df with population df\n",
    "merged_df = pm25_per_state.merge(state, on='state', how='outer')\n",
    "#added new column of percapita pm25 pollution\n",
    "merged_df[\"population_Density\"]=merged_df[\"Population\"]/merged_df[\"Area (km2)\"]\n",
    "#sorting pm25 in descending\n",
    "\n",
    "d= (merged_df['state']==\"Maharashtra\") | (merged_df['state']==\"Madhya Pradesh\")\n",
    "#print(d)\n",
    "#bargraph\n",
    "bargraph1= plt.pyplot\n",
    "bargraph1.bar(merged_df[d][\"state\"], merged_df[d]['PM2.5'])\n",
    "bargraph1.xlabel(\"State\")\n",
    "bargraph1.ylabel(\"average PM2.5 levels\")\n",
    "bargraph1.tight_layout()\n",
    "bargraph1.show()\n",
    "\n",
    "bargraph2= plt.pyplot\n",
    "bargraph2.bar(merged_df[d][\"state\"], merged_df[d]['population_Density'])\n",
    "bargraph2.xlabel(\"State\")\n",
    "bargraph2.ylabel(\"population density\")\n",
    "bargraph2.tight_layout()\n",
    "bargraph2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3128ff3-598e-4ca8-aa6f-5bab5eee9c9d",
   "metadata": {},
   "source": [
    "## Funding Based  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df15d8d-a8bc-458f-98d1-0fefce7ac9fa",
   "metadata": {},
   "source": [
    "#### Compare the average PM2.5 levels between states that received NCAP funding and those that did not in 2021.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79cd8a-6e39-4167-97a4-797a6d63b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Timestamp\"] = pd.to_datetime(data[\"Timestamp\"], errors='coerce')\n",
    "ncap_data[\"Total fund released\"] = pd.to_numeric(ncap_data[\"Total fund released\"], errors='coerce')\n",
    "\n",
    "funded_states = ncap_data[ncap_data[\"Total fund released\"] > 0][\"State\"].unique()\n",
    "state_data[\"NCAP_Funded\"] = state_data[\"State\"].apply(lambda x: \"Funded\" if x in funded_states else \"Non-Funded\")\n",
    "df_2021 = data[data[\"Timestamp\"].dt.year == 2021]\n",
    "df_2021 = df_2021.dropna(subset=[\"PM2.5\", \"state\"])\n",
    "pm25_funding_comparison = data.merge(state_data[[\"State\", \"NCAP_Funded\"]],left_on=\"state\", right_on=\"State\", how=\"left\")\n",
    "pm25_comparison = pm25_funding_comparison.groupby(\"NCAP_Funded\")[\"PM2.5\"].mean()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(pm25_comparison.index, pm25_comparison.values, color=['red', 'green'])\n",
    "\n",
    "plt.xlabel(\"NCAP Funding Status\")\n",
    "plt.ylabel(\"Average PM2.5 (µg/m³)\")\n",
    "plt.title(\"Comparison of PM2.5 Levels in Funded vs Non-Funded States (2021)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0b96e-48f9-4fc4-95e3-91c62a165f14",
   "metadata": {},
   "source": [
    "#### Create a time series plot showing PM2.5 levels with an increment in NCAP funding for Assam. Has an increment of the financing led to noticeable improvements in air quality?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81b23e-3747-4dbe-a601-f3e369af7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assam_air_quality = data[data['state'] == 'Assam'].copy()\n",
    "assam_ncap_funding = ncap_data[ncap_data['State'] == 'Assam']\n",
    "\n",
    "assam_air_quality.loc[:,'Year'] = assam_air_quality['Timestamp'].dt.year\n",
    "pm25_yearly = assam_air_quality.groupby('Year')['PM2.5'].mean().reset_index()\n",
    "\n",
    "assam_ncap_funding = assam_ncap_funding[['Year', 'Total fund released']]\n",
    "\n",
    "merged_data = pd.merge(pm25_yearly, assam_ncap_funding, on='Year', how='left')\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Average PM2.5 (µg/m³)', color='tab:blue')\n",
    "ax1.plot(merged_data['Year'], merged_data['PM2.5'], color='tab:blue', label='PM2.5 Levels', marker='o')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Total NCAP Funding', color='green')\n",
    "ax2.plot(merged_data['Year'], merged_data['Total fund released'], color='green', label='NCAP Funding', marker='x')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "plt.title('PM2.5 Levels and NCAP Funding for Assam (Yearly)', fontsize=14)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d28719-a34d-41b9-b723-875460c0998b",
   "metadata": {},
   "source": [
    "#### Create a scatter plot to showcase the area versus funding received by a state. Mark every state with a different color and show the legend outside the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d623ca-7682-4305-8ea6-9eebc63752db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Total fund released\"]:\n",
    "    df_2[col] = pd.to_numeric(df_2[col], errors=\"coerce\")\n",
    "\n",
    "state_funding = df_2.groupby(\"state\")[\"Total fund released\"].sum().reset_index()\n",
    "state_funding = state_funding.merge(df1, on=\"state\", how=\"left\") \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = sns.scatterplot(\n",
    "    data=state_funding,\n",
    "    x=\"Area (km2)\", \n",
    "    y=\"Total fund released\", \n",
    "    hue=\"state\",  \n",
    "    palette=\"tab20\",\n",
    "    s=100,  \n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f79c638-f1a8-41c9-ab23-458f4ef9c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbdb2eca-bc3f-455f-a9de-f80d3bc27abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_2023 \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2023\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Step 3: Calculate the average PM2.5 levels for each city in 2023\u001b[39;00m\n\u001b[0;32m      4\u001b[0m average_pm25_city \u001b[38;5;241m=\u001b[39m df_2023\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPM2.5\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_2023 = data[data['Timestamp'].dt.year == 2023]\n",
    "\n",
    "# Step 3: Calculate the average PM2.5 levels for each city in 2023\n",
    "average_pm25_city = df_2023.groupby('city')['PM2.5'].mean()\n",
    "\n",
    "# Step 4: Find the city with the highest average PM2.5 level\n",
    "most_polluted_city = average_pm25_city.idxmax()\n",
    "highest_avg_pm25 = average_pm25_city.max()\n",
    "\n",
    "# Step 5: Filter data for the most polluted city\n",
    "city_data = df_2023[df_2023['city'] == most_polluted_city]\n",
    "\n",
    "# Step 6: Calculate the number of days with PM2.5 above 300 µg/m³\n",
    "hazardous_days = city_data[city_data['PM2.5'] > 300].shape[0]\n",
    "\n",
    "# Step 7: Calculate the total number of days for the city\n",
    "total_days = city_data['Timestamp'].nunique()\n",
    "\n",
    "# Step 8: Calculate the percentage of hazardous days\n",
    "hazardous_percentage = (hazardous_days / total_days) * 100\n",
    "\n",
    "# Step 9: Output the results\n",
    "print(f\"Most polluted city in 2023: {most_polluted_city}\")\n",
    "print(f\"Highest average PM2.5 level: {highest_avg_pm25:.2f} µg/m³\")\n",
    "print(f\"Percentage of hazardous days (PM2.5 > 300 µg/m³) in {most_polluted_city}: {hazardous_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60c0dd9f-586e-45fb-abd8-ffc5689d0f89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m      4\u001b[0m df_diwali\u001b[38;5;241m=\u001b[39mdf[(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m11\u001b[39m]))\u001b[38;5;241m&\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m2018\u001b[39m,\u001b[38;5;241m2019\u001b[39m,\u001b[38;5;241m2020\u001b[39m]))]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"month\"]=df[\"Timestamp\"].dt.month\n",
    "df[\"year\"]=df[\"Timestamp\"].dt.year\n",
    "\n",
    "df_diwali=df[(df[\"month\"].isin([10,11]))&(df[\"year\"].isin([2018,2019,2020]))]\n",
    "diwali_average=df_diwali[\"PM2.5\"].mean()\n",
    "print(f\"Average PM2.5 levels during diwali were {diwali_average} units.\")\n",
    "\n",
    "df_newyear=df[(df[\"Timestamp\"].dt.month==1)&(df[\"Timestamp\"].dt.day==1)&(df[\"year\"].isin([2018,2019,2020]))]\n",
    "newyear_average=df_newyear[\"PM2.5\"].mean()\n",
    "print(f\"Average PM2.5 levels during New year were {newyear_average} units.\")\n",
    "\n",
    "df_normal=df[(df[\"month\"].isin([2,3,4,5,6,7,8,9,12]))&(df[\"year\"].isin([2018,2019,2020]))]\n",
    "normal_average=df_normal[\"PM2.5\"].mean()\n",
    "print(f\"Average PM2.5 levels in rest of the year were {normal_average} units.\")\n",
    "\n",
    "plt.plot(df_diwali[\"Timestamp\"], df_diwali[\"PM2.5\"], color=\"red\", label=\"Diwali\")\n",
    "plt.annotate(\"Diwali\", xy=(df_diwali[\"Timestamp\"].median(), diwali_average),xytext=(df_diwali[\"Timestamp\"].median(), diwali_average + 50),arrowprops=dict(facecolor=\"red\", arrowstyle=\"->\"))\n",
    "\n",
    "plt.plot(df_newyear[\"Timestamp\"], df_newyear[\"PM2.5\"], color=\"blue\", label=\"New Year\")\n",
    "plt.annotate(\"New Year\", xy=(df_newyear[\"Timestamp\"].median(), newyear_average),xytext=(df_newyear[\"Timestamp\"].median(), newyear_average + 50),arrowprops=dict(facecolor=\"blue\", arrowstyle=\"->\"))\n",
    "\n",
    "plt.xlabel(\"Timeline\")\n",
    "plt.ylabel(\"PM2.5 Level\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "577edf17-6dbf-40e0-bf69-ece04c8bd102",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpl_toolkits.basemap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasemap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Basemap\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the map\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Initialize the map\n",
    "plt.figure(figsize=(10, 6))\n",
    "m = Basemap(projection=\"mill\", llcrnrlat=5, urcrnrlat=35, llcrnrlon=65, urcrnrlon=100, resolution=\"l\")\n",
    "\n",
    "# Draw map details\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawmapboundary(fill_color=\"aqua\")\n",
    "m.fillcontinents(color=\"lightgray\", lake_color=\"aqua\")\n",
    "\n",
    "# Convert lat/lon to map coordinates\n",
    "if \"lat\" in df.columns and \"lon\" in df.columns:\n",
    "    x, y = m(df[\"lon\"].values, df[\"lat\"].values)\n",
    "    plt.scatter(x, y, c=df[\"PM2.5\"], cmap=\"Reds\", marker=\"o\", alpha=0.7)\n",
    "    plt.colorbar(label=\"PM2.5 Level (µg/m³)\")\n",
    "\n",
    "plt.title(\"Air Quality Monitoring Stations in India\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a641f1e7-e48e-469e-8ca0-7947dbac810b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m india_boundary\u001b[38;5;241m=\u001b[39mox\u001b[38;5;241m.\u001b[39mgeocode_to_gdf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m sensor_locations\u001b[38;5;241m=\u001b[39mdf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      4\u001b[0m fig, ax\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ox' is not defined"
     ]
    }
   ],
   "source": [
    "india_boundary=ox.geocode_to_gdf(\"India\")\n",
    "sensor_locations=df[['latitude', 'longitude', 'station']].dropna()\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(10, 10))\n",
    "india_boundary.plot(ax=ax, color='lightgreen', edgecolor='black')\n",
    "ax.scatter(sensor_locations['longitude'], sensor_locations['latitude'], \n",
    "           color='black', marker='^', s=50, edgecolors='white', label='Sensor Locations')\n",
    "ax.set_title('Sensor Locations in India', fontsize=12)\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743f172-e280-4392-a7ed-d84295078c11",
   "metadata": {},
   "source": [
    "## Tell us something new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdcf4550-9851-4014-a074-d1b13ddbcb82",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3817711646.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[32], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install cartopy\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "data.rename(columns={\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}, inplace=True)\n",
    "\n",
    "sensor_locations = data.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=\"--\", linewidth=1)\n",
    "ax.add_feature(cfeature.LAND, color=\"skyblue\")\n",
    "ax.set_extent([68, 98, 6, 38])\n",
    "\n",
    "plt.scatter(sensor_locations[\"longitude\"], sensor_locations[\"latitude\"], color=\"red\", s=10, label=\"Sensor Locations\", transform=ccrs.PlateCarree())\n",
    "plt.title(\"India - PM2.5 Sensor Locations\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
